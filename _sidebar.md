<!-- _sidebar.md -->

* [ğŸ  é¦–é¡µ](README.md)

* **ğŸ“– ä½¿ç”¨æŒ‡å—**
  * [å¿«é€Ÿå¼€å§‹](docs_md/guide/quickstart.md)
  * [åŸºç¡€é…ç½®](docs_md/guide/configuration.md)

* **ğŸ¤– AIæŠ€æœ¯ç§‘æ™®ï¼ˆæ¥æºï¼šone-small-stepï¼‰**
  * [é¡¹ç›®ä»‹ç»](docs_md/one-small-step/README.md)
  * **ğŸ§  å¤§è¯­è¨€æ¨¡å‹åŸºç¡€**
    * [ä»€ä¹ˆæ˜¯ GGUF](docs_md/one-small-step/20250113-what-is-gguf/what-is-gguf.md)
    * [ä»€ä¹ˆæ˜¯ Transformer](docs_md/one-small-step/20250126-what-is-transformer/what-is-transformer.md)
    * [ä»€ä¹ˆæ˜¯å¤§è¯­è¨€æ¨¡å‹é‡åŒ–](docs_md/one-small-step/20250129-what-is-quantization-in-LLM/what-is-quantization-in-LLM.md)
    * [ä»€ä¹ˆæ˜¯ Safetensors](docs_md/one-small-step/20250210-what-is-safetensors/what-is-safetensors.md)
    * [ä»€ä¹ˆæ˜¯ ONNX](docs_md/one-small-step/20250211-what-is-onnx/what-is-onnx.md)
  * **âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯**
    * [ä»€ä¹ˆæ˜¯æ¨æµ‹æ€§è§£ç ](docs_md/one-small-step/20250116-what-is-speculative-decoding/what-is-speculative-decoding.md)
    * [å¦‚ä½•ä¼˜åŒ– Transformer](docs_md/one-small-step/20250127-how-to-optimize-transformer/how-to-optimize-transformer.md)
    * [ä»€ä¹ˆæ˜¯ Flash Attention](docs_md/one-small-step/20250201-what-is-flash-attention/what-is-flash-attention.md)
    * [ä»€ä¹ˆæ˜¯ Sliding Window Attention](docs_md/one-small-step/20250522-what-is-sliding-window-attention/what-is-sliding-window-attention.md)
    * [å¦‚ä½•é¿å… KVCache å¤±æ•ˆ](docs_md/one-small-step/20250513-How-to-avoid-KVCache-invalidation/How-to-avoid-KVCache-invalidation.md)
  * **ğŸ¯ æ³¨æ„åŠ›æœºåˆ¶**
    * [ä»€ä¹ˆæ˜¯ Multi-Head Attention](docs_md/one-small-step/20250202-what-is-multi-head-attention/what-is-multi-head-attention.md)
    * [ä»€ä¹ˆæ˜¯ Multi-Query Attention](docs_md/one-small-step/20250204-what-is-multi-query-attention/what-is-multi-query-attention.md)
    * [ä»€ä¹ˆæ˜¯ Grouped Query Attention](docs_md/one-small-step/20250205-what-is-gropued-query-attention/what-is-gropued-query-attention.md)
  * **ğŸ”§ æ¨¡å‹è®­ç»ƒä¸å¾®è°ƒ**
    * [ä»€ä¹ˆæ˜¯ LLM å¾®è°ƒæŠ€æœ¯](docs_md/one-small-step/20250208-what-is-LLM-fine-tuning/what-is-LLM-fine-tuning.md)
    * [ä»€ä¹ˆæ˜¯ LLM è’¸é¦æŠ€æœ¯](docs_md/one-small-step/20250123-what-is-LLM-distill/what-is-LLM-distill.md)
    * [ä»€ä¹ˆæ˜¯ LoRA](docs_md/one-small-step/20250228-what-is-LoRA/what-is-LoRA.md)
    * [å¤§æ¨¡å‹å¾®è°ƒæœ€ä½³å®è·µæŒ‡å—](docs_md/one-small-step/20250210-LLM-fine-tuning-summary/LLM-fine-tuning-summary.md)
    * [ä»€ä¹ˆæ—¶å€™åº”è¯¥å¾®è°ƒ](docs_md/one-small-step/20250530-When-to-Use-Fine-Tuning-and-When-Not-To/When-to-Use-Fine-Tuning-and-When-Not-To.md)
    * [ä»€ä¹ˆæ˜¯æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ](docs_md/one-small-step/20250301-what-is-fitting-and-overfitting/what-is-fitting-and-overfitting.md)
  * **ğŸ—ï¸ é«˜çº§æ¶æ„**
    * [ä»€ä¹ˆæ˜¯ MoE æ¨¡å‹](docs_md/one-small-step/20250217-what-is-MoE/what-is-MoE-model.md)
    * [ä»€ä¹ˆæ˜¯å¤šæ¨¡æ€æ¨¡å‹](docs_md/one-small-step/20250317-what-is-multi-model-llm/what-is-multi-model-llm.md)
    * [ä»€ä¹ˆæ˜¯æ¨¡æ€ç¼–ç ](docs_md/one-small-step/20250315-what-is-modal-encoding/what-is-modal-encoding.md)
    * [ä»€ä¹ˆæ˜¯è¡¨ç¤ºç©ºé—´](docs_md/one-small-step/20250316-what-is-representation-space/what-is-representation-space.md)
  * **ğŸ” åº”ç”¨æŠ€æœ¯**
    * [ä»€ä¹ˆæ˜¯ RAG æŠ€æœ¯](docs_md/one-small-step/20250209-what-is-RAG/what-is-RAG.md)
    * [ä»€ä¹ˆæ˜¯å‘é‡åµŒå…¥](docs_md/one-small-step/20250307-what-is-vector-embedding/what-is-vector-embedding.md)
    * [ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“](docs_md/one-small-step/20250308-what-is-vector-database/what-is-vector-database.md)
    * [ä»€ä¹ˆæ˜¯ AI Agent](docs_md/one-small-step/20250220-what-is-AI-Agent/what-is-AI-Agent.md)
    * [ä»€ä¹ˆæ˜¯ Pythonic å‡½æ•°è°ƒç”¨](docs_md/one-small-step/20250117-what-is-pythonic-function-call/what-is-pythonic-function-call.md)
  * **ğŸ“Š è¯„ä¼°ä¸åˆ†æ**
    * [LLM ä¸­çš„ Token æ˜¯å¦‚ä½•è®¡ç®—çš„](docs_md/one-small-step/20250218-how-are-tokens-calculated-in-LLMs/how-are-tokens-calculated-in-LLMs.md)
    * [ä»€ä¹ˆæ˜¯ LLM çš„å›°æƒ‘åº¦](docs_md/one-small-step/20250403-what-is-llm-perplexity/what-is-llm-perplexity.md)
    * [ä»€ä¹ˆæ˜¯ AI å¹»è§‰](docs_md/one-small-step/20250309-what-is-AI-Hallucination/what-is-AI-Hallucination.md)
  * **ğŸ’» å®è·µæŒ‡å—**
    * [å¦‚ä½•æœ¬åœ°è¿è¡Œ GGUF æ ¼å¼çš„ LLM æ¨¡å‹](docs_md/one-small-step/20250122-how-to-run-gguf-LLM-model/how-to-run-gguf-LLM-model.md)
  * **ğŸ”¢ æ•°å­¦åŸºç¡€**
    * [ä»€ä¹ˆæ˜¯çŸ©é˜µçš„ç§©](docs_md/one-small-step/20250227-what-is-rank-in-matrix/what-is-rank-in-matrix.md)
  * **ğŸ’¾ ç¡¬ä»¶ç›¸å…³**
    * [Windowsä»»åŠ¡ç®¡ç†å™¨å†…å­˜é€‰é¡¹å¡è¯´æ˜](docs_md/one-small-step/20250104-windows-task-manager-memory-tab-description/windows-task-manager-memory-tab-description.md)
    * [ä»€ä¹ˆæ˜¯ PCIe Retimer](docs_md/one-small-step/20250119-what-is-pcie-retimer/what-is-pcie-retimer.md)
    * [ä¸ºä»€ä¹ˆæœ‰äº› NVMe SSD æœ‰ DRAM](docs_md/one-small-step/20250124-why-some-NVMe-SSD-have-DRAM-and-some-are-not/why-some-NVMe-SSD-have-DRAM-and-some-are-not.md)
    * [CXL ä¼šæ˜¯ LLM å†…å­˜è§£å†³æ–¹æ¡ˆå—](docs_md/one-small-step/20250125-does-CXL-will-be-LLM-memory-solution/does-CXL-will-be-LLM-memory-solution.md)
    * [RamMap å·¥å…·è¯´æ˜](docs_md/one-small-step/20250128-rammap-description/rammap-description.md)
    * [ä»€ä¹ˆæ˜¯ 1DPC](docs_md/one-small-step/20250131-what-is-1DPC/what-is-1DPC.md)
    * [ä»€ä¹ˆæ˜¯ L1 ç¼“å­˜](docs_md/one-small-step/20250206-what-is-L1-cache/what-is-L1-cache.md)

* **ğŸ”— èµ„æºé“¾æ¥**
  * [å®˜æ–¹æ–‡æ¡£](https://docsify.js.org/)
  * [GitHubä»“åº“](https://github.com/docsifyjs/docsify)
  * [é€‰é¢˜åˆ—è¡¨](docs_md/one-small-step/topic.md)